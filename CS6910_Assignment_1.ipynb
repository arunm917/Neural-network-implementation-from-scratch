{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_Aqal939HNhx",
        "xGDKTaMUQK1C",
        "5RH_78eMoUz_"
      ],
      "authorship_tag": "ABX9TyNFzZX6FX2A5GUS8W38ljX7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunm917/CS6910_Assignment1/blob/main/CS6910_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages"
      ],
      "metadata": {
        "id": "_Aqal939HNhx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3iv-dm8IHFiD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as ts\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "xGDKTaMUQK1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.asarray([[2.5, 2.5], [4, -1], [1, -4], [-3, 1.25], [-2, -4], [1, 5]])\n",
        "# Y = [1, 1, 1, 0, 0, 0]\n",
        "# downloading existing perovskite file from gdrive\n",
        "output = 'mobile data'\n",
        "file_id = '14ZgjTbautWSaKS3EhkK6HzfLE_qeGRx9' # Google drive ID\n",
        "#Download the file\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, quiet=False)\n",
        "print('DONE.')"
      ],
      "metadata": {
        "id": "w5VKNGSNQJ86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0593bfe3-fbfc-4dd1-8965-6f179362a38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14ZgjTbautWSaKS3EhkK6HzfLE_qeGRx9\n",
            "To: /content/mobile data\n",
            "100%|██████████| 69.7k/69.7k [00:00<00:00, 7.95MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('mobile data')"
      ],
      "metadata": {
        "id": "3PHHHFDKjREq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IVlg9MJkCMc",
        "outputId": "673349f8-7f04-4624-e749-3011cfe0f703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(341, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Rating', axis = 1)"
      ],
      "metadata": {
        "id": "4rUHq4IPlrAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data['Rating'].values # Rating is out of 5"
      ],
      "metadata": {
        "id": "xHehNTgBmL-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAKp5OTbnAiB",
        "outputId": "ad9be638-f315-43e5-a634-da9d0b31ddd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.5, 4.5, 4.4, 4.3, 4.4, 4.5, 4.3, 4.1, 4.3, 4.5, 4.5, 4. , 4.4,\n",
              "       4.4, 4.4, 4.4, 4.5, 4.4, 4.4, 4.4, 4.4, 4.5, 4.4, 4.3, 4.2, 4.3,\n",
              "       4.3, 4.6, 4.4, 4.5, 3.9, 4.2, 4.3, 4.2, 4.3, 4.3, 4.2, 4.4, 4.1,\n",
              "       3.8, 4.4, 4.6, 4.3, 4.5, 4.5, 4.2, 3.9, 4.3, 4. , 4.3, 4.3, 3.9,\n",
              "       4.2, 4.5, 4. , 4.6, 4.2, 2.8, 4.4, 4.3, 4.2, 4.4, 4.4, 4. , 4.4,\n",
              "       4.4, 4.1, 4.5, 4.3, 3.9, 4.3, 4.1, 4.1, 4.2, 3.4, 4.2, 4.6, 3.8,\n",
              "       4.3, 4.5, 4.2, 4.5, 4.5, 4. , 4.1, 4.4, 4.5, 4.1, 4.5, 4.3, 4.5,\n",
              "       3.9, 3.9, 4.4, 4.4, 4.4, 4. , 4.1, 4.1, 4.4, 4.3, 4.3, 4.2, 4.3,\n",
              "       3.4, 4.3, 4.3, 4.2, 4.6, 4.8, 4.4, 3.4, 3.7, 4.2, 4.3, 4.4, 4.3,\n",
              "       4.2, 4.1, 4.3, 4. , 3.9, 4.4, 4.4, 3.9, 3.1, 3.7, 4.2, 4.4, 4. ,\n",
              "       4. , 4.1, 4.2, 4.3, 4.2, 4.3, 4.1, 3.6, 4.1, 4. , 3.8, 3.7, 4.3,\n",
              "       4.1, 4.1, 4.5, 4. , 4.3, 3.6, 4.1, 4.5, 3.5, 4. , 4.3, 4.6, 3.5,\n",
              "       3.9, 4.1, 3.9, 3.8, 4.4, 4.3, 4. , 3.9, 4.4, 4.7, 3.9, 4.5, 3.7,\n",
              "       4. , 4.3, 4.1, 4.8, 4.1, 4. , 4.7, 4. , 4.1, 4. , 3.4, 4.1, 3.9,\n",
              "       3.1, 4.1, 3.7, 3.4, 3.9, 4.3, 4.1, 3.7, 3.8, 4. , 3.8, 4.6, 3.4,\n",
              "       3.3, 3.2, 3.5, 4.3, 4.1, 4. , 3.8, 4.3, 4.1, 4. , 3.8, 3.8, 3.9,\n",
              "       4.1, 3.7, 4.2, 4. , 4.2, 4.4, 4.1, 3.4, 4.2, 4.4, 3.9, 3.9, 4.4,\n",
              "       4.2, 4.5, 4.5, 4.2, 4. , 4.2, 3.5, 3.7, 4.3, 5. , 3.5, 4.4, 3.7,\n",
              "       4.3, 3.9, 4.3, 3.8, 3.8, 4.3, 5. , 4.1, 3. , 4.4, 3. , 4. , 4. ,\n",
              "       3.9, 3.9, 4.2, 2.8, 4.3, 3.3, 4.3, 4. , 4.2, 4.1, 4.2, 3.6, 3.5,\n",
              "       4.1, 4.6, 3.9, 4. , 3.8, 4.1, 2.5, 4.2, 3.7, 3.9, 4.1, 3. , 3.8,\n",
              "       4.6, 4.2, 3.4, 3.9, 4.5, 4.1, 3.3, 4.1, 4. , 3.3, 4.4, 3.8, 3.9,\n",
              "       3.6, 4.4, 4.1, 4.1, 4. , 3.5, 3. , 4.2, 4. , 3.9, 3.5, 3.4, 3.4,\n",
              "       4. , 3.6, 4. , 3.5, 4. , 4. , 3.7, 4.6, 4. , 4.1, 4. , 3.5, 4.1,\n",
              "       3.7, 4.4, 4.3, 4.1, 3.9, 3.4, 3.3, 3.9, 4. , 4.4, 4.5, 4.2, 3.8,\n",
              "       3.7, 4.2, 4.1, 4. , 3.9, 3.7, 4.2, 4. , 3.6, 3.6, 4.4, 3.8, 3.9,\n",
              "       4.1, 3.6, 4.3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 4.2\n",
        "data['class'] = (data['Rating'] >= threshold).astype(np.int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QJ-516GmcqD",
        "outputId": "2e9e62bd-532e-4c3d-f8ee-88010fffe39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-34a1b5c4b940>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data['class'] = (data['Rating'] >= threshold).astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['class'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcdyPzcrpNuf",
        "outputId": "7ae0ac9b-6613-42ea-aeda-b3c6e0ce5f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.533724\n",
              "1    0.466276\n",
              "Name: class, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_binarised = data['class'].values"
      ],
      "metadata": {
        "id": "aPI16P8tqPk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, random_state = 0, stratify = Y_binarised)"
      ],
      "metadata": {
        "id": "TAfx7KayqXFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW2xrQlDtwAC",
        "outputId": "3357071b-820b-4911-a003-660bb32b7890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(255, 87)\n",
            "(86, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standardization"
      ],
      "metadata": {
        "id": "ndGbbKocqY-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_train = scaler.fit_transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "hXdvgzButqyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minmax_scaler = MinMaxScaler()\n",
        "Y_scaled_train = minmax_scaler.fit_transform(Y_train.reshape(-1,1))\n",
        "Y_scaled_test = minmax_scaler.transform(Y_test.reshape(-1,1))"
      ],
      "metadata": {
        "id": "GGMoZWD_xpJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_threshold = list(minmax_scaler.transform(np.array([threshold]).reshape(1, -1)))[0][0]"
      ],
      "metadata": {
        "id": "7RKYrKAT3PN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_binarised_train = (Y_scaled_train > scaled_threshold).astype(\"int\").ravel()\n",
        "Y_binarised_test = (Y_scaled_test > scaled_threshold).astype(\"int\").ravel()"
      ],
      "metadata": {
        "id": "3ZKRymhr3SLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atqqPbN0oS7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing - fashion MNIST"
      ],
      "metadata": {
        "id": "5RH_78eMoUz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "L9o4nbueocl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449fb6f8-b138-4b6b-b950-04ce78218d23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=7, test_size = 0.2)"
      ],
      "metadata": {
        "id": "q42AW6dqE3jt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEqazuKsGqR8",
        "outputId": "c2f509e8-8710-400f-bf71-d82e108d872e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train.reshape(len(X_train),28*28)/255.0\n",
        "X_val_scaled = X_val.reshape(len(X_val),28*28)/255.0\n",
        "X_test_scaled = X_test.reshape(len(X_test),28*28)/255.0"
      ],
      "metadata": {
        "id": "1lOnsGYSq0YV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding labels"
      ],
      "metadata": {
        "id": "RCN_Xp6OHz8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder()\n",
        "y_train_enc = enc.fit_transform(np.expand_dims(y_train,1)).toarray()\n",
        "y_val_enc = enc.fit_transform(np.expand_dims(y_val,1)).toarray()\n",
        "y_test_enc = enc.fit_transform(np.expand_dims(y_test,1)).toarray()\n",
        "print(y_train_enc.shape, y_val_enc.shape, y_test_enc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHgfHPrWHNJ_",
        "outputId": "9b71798a-f36e-4782-d113-90c2553ce039"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 10) (12000, 10) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializations"
      ],
      "metadata": {
        "id": "F9mmePvZHTlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Initialization:\n",
        "#   W = np.random.randn(1, X_scaled_train.shape[1])\n",
        "#   b = 0\n",
        "  \n",
        "# initial = Initialization()  #Instantiation for the class initialization"
      ],
      "metadata": {
        "id": "uoZUDSWvHcSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "FURanER4HgN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Hyperparameters:\n",
        "  epochs = 10\n",
        "  eta    = 0.05\n",
        "\n",
        "hyper = Hyperparameters()"
      ],
      "metadata": {
        "id": "0OjAzV-QH-rH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation functions"
      ],
      "metadata": {
        "id": "zQAFW9LhIHSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationFunctions:\n",
        "\n",
        "  def linear(self,W,b,x):\n",
        "    return (np.dot(W,x) + b)\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def softmax(self, z):\n",
        "    return np.exp(z)/np.sum(np.exp(z))\n",
        "  \n",
        "  def grad_sigmoid(self,z):\n",
        "    return z*(1-z)\n",
        "\n",
        "\n",
        "act = ActivationFunctions()"
      ],
      "metadata": {
        "id": "gaYebnsAIJXs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions"
      ],
      "metadata": {
        "id": "1iklJTyvIPQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "  def MSE(self, y, y_pred):\n",
        "    return (np.sum((y-y_pred)**2))/len(y)\n",
        "  \n",
        "  #def cross_entropy(self, y, y_pred):\n",
        "    \n",
        "loss = Loss()"
      ],
      "metadata": {
        "id": "Ysm6kTMgIS42"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradients"
      ],
      "metadata": {
        "id": "_uz-ncklIgSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gradients():\n",
        "\n",
        "  def grad_w (self, W, b, x, y):\n",
        "      y_pred = act.sigmoid(W, b, x)\n",
        "      #print('y_pred',y_pred)\n",
        "      return (y_pred - y)*y_pred*(1-y_pred)*x\n",
        "  \n",
        "  def grad_b (self, W, b, x, y):\n",
        "      y_pred = act.sigmoid(W, b, x)\n",
        "      return (y_pred - y)*y_pred*(1-y_pred)\n",
        "\n",
        "# grad = Gradients()"
      ],
      "metadata": {
        "id": "L4SX4XEaIqM3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward popagation"
      ],
      "metadata": {
        "id": "km6C0oq-IyOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForwardPropagation:\n",
        "\n",
        "  def forward_prop(self, x, hidden_layer_sizes):\n",
        "    self.x = x\n",
        "    self.nx = len(x)\n",
        "    self.ny = 10\n",
        "    self.nh = len(hidden_layer_sizes)\n",
        "    self.sizes = [self.nx] + hidden_layer_sizes + [self.ny]\n",
        "    # print(self.sizes)\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    for i in range(self.nh + 1):\n",
        "      self.W[i+1] = np.random.randn(self.sizes[i+1], self.sizes[i])\n",
        "      self.B[i+1] = np.zeros((self.sizes[i+1],1))\n",
        "    \n",
        "    # print('W',self.W)\n",
        "    # print('B',self.B)\n",
        "\n",
        "    self.H[0] = self.x.reshape(-1,1)\n",
        "    for i in range(self.nh + 1):\n",
        "      self.A[i+1] = np.matmul(self.W[i+1], self.H[i]) + self.B[i+1] \n",
        "      self.H[i+1] = act.sigmoid(self.A[i+1])\n",
        "\n",
        "    y_pred = act.softmax(self.A[i+1])\n",
        "    print(y_pred)\n",
        "    return(y_pred)"
      ],
      "metadata": {
        "id": "m78pqHeerZZ3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward = ForwardPropagation()\n",
        "#forward.forward_prop()"
      ],
      "metadata": {
        "id": "fp588nCqAjCK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation"
      ],
      "metadata": {
        "id": "ZWrleHFJu_su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gradients(ForwardPropagation):\n",
        "\n",
        "  def grad(self, x, y, hidden_layer_sizes):\n",
        "\n",
        "    self.forward_prop(x, hidden_layer_sizes)\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dA = {}\n",
        "    self.dH = {}\n",
        "    self.dW_sum = {}\n",
        "    self.dB_sum = {}\n",
        "    self.loss_gd = []\n",
        "    \n",
        "    self.dA[self.nh + 1] = self.H[self.nh + 1] - Y.T\n",
        "\n",
        "    for i in range(self.nh + 1 , 1):  \n",
        "      self.dW[i]      = np.matmul(self.dA[i],self.H[i-1].T)\n",
        "      self.dW_sum[i] += self.dW[i]  \n",
        "      self.dB[i]      = self.dA[i]\n",
        "      self.dB_sum[i] += self.dB[i]\n",
        "      self.dH[i-1]    = np.matmul(self.W[i+1].T,self.dA[i])\n",
        "      self.dA[i-1]    = np.matmul(self.dH[i-1],act.grad_sigmoid(self.H[i-1]))\n",
        "    return (self.dW_sum, self.dB_sum)\n",
        "\n",
        "  def fit(self, X, Y, epochs, learning_rate, hidden_layer_sizes):\n",
        "    for i in trange(hyper.epochs, total=hyper.epochs, unit=\"epoch\"):\n",
        "      grad_W = 0\n",
        "      grad_B = 0\n",
        "      m = len(X)\n",
        "\n",
        "      for x,y in zip(X,Y):\n",
        "        x = x.reshape(1,-1)\n",
        "        self.grad(x,y, hidden_layer_sizes)\n",
        "      \n",
        "      for i in range(self.nh + 1):\n",
        "        self.W[i+1] -= learning_rate * (self.dW[i+1]/m)\n",
        "        self.B[i+1] -= learning_rate * (self.dB[i+1]/m)\n",
        "      \n",
        "      y_pred = self.forward_prop(x, hidden_layer_sizes)\n",
        "      self.loss_gd[i] = log_loss(y_pred,y)\n",
        "    \n",
        "    plt.plot(self.loss_gd)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('log_loss')\n",
        "    plt.show()\n",
        "\n",
        "grad = Gradients()"
      ],
      "metadata": {
        "id": "9F7QZzMiu75e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad.fit(X_train_scaled, y_train_enc, hyper.epochs, hyper.eta, [512, 512])"
      ],
      "metadata": {
        "id": "wqISZGEjvyoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Algorithms"
      ],
      "metadata": {
        "id": "ZQGzzm1ZIVsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningAlgorithms:\n",
        "\n",
        "  def gd(self, X, Y):\n",
        "\n",
        "    loss_gd = []\n",
        "\n",
        "    for i in trange(hyper.epochs, total=hyper.epochs, unit=\"epoch\"):\n",
        "      dw = 0\n",
        "      db = 0\n",
        "      \n",
        "      for x,y in zip(X,Y):\n",
        "        x = x.reshape(1,-1)\n",
        "        dw += grad.grad_w(W,b,x,y)\n",
        "        db += grad.grad_b(W,b,x,y)\n",
        "\n",
        "      W -= hyper.eta*dw\n",
        "      b -= hyper.eta*db\n",
        "      Y_pred = act.sigmoid(W, b, x)\n",
        "      loss_gd.append(loss.MSE(Y, Y_pred))\n",
        "      #print('W',W,'b',b)\n",
        "      #print('loss', loss.MSE(Y, Y_pred))\n",
        "\n",
        "    plt.plot(loss_gd)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.show()\n",
        "\n",
        "la = LearningAlgorithms()"
      ],
      "metadata": {
        "id": "ps_e-AyMIYzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "I8OKth2D6jFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class train:\n",
        "  def fit(self, X, Y, epochs, learning_rate, hidden_layer_sizes):\n",
        "      for i in trange(hyper.epochs, total=hyper.epochs, unit=\"epoch\"):\n",
        "        grad_W = 0\n",
        "        grad_B = 0\n",
        "        for x,y in zip(X,Y):\n",
        "          x = x.reshape(1,-1)\n",
        "          (self.dw, self.db) = self.grad(x,y)\n",
        "          grad_W += self.dw\n",
        "          grad_B += self.db"
      ],
      "metadata": {
        "id": "1-E9UdepYB1D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}